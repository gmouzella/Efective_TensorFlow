{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_EfectiveTensorFlow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmouzella/Efective_TensorFlow/blob/master/Tutorial_EfectiveTensorFlow(portugu%C3%AAs).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "p1CnaZ9y6AsO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Effective TensorFlow\n",
        "\n",
        "Esta artigo foi orignalmente escrito por [Vahid Kazemi](https://github.com/vahidk). Para acessar o artigo original [clique aqui](https://github.com/vahidk/EffectiveTensorflow)."
      ]
    },
    {
      "metadata": {
        "id": "svoXy2DAAuBW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Indicações <a name=\"indicacoes\"></a>\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "fTkWO5SpeULv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dicas  execução**\n",
        "* Carregue todos os pacotes que serão necessários no início do arquivo.\n",
        "* Para executar comandos da shell dentro do notebook, utilize o prefixo `!` antes do comando de shell. (e.g. para listar os arquivos da pasta atual faça `! ls` para UNIX ou `! dir` para Windows."
      ]
    },
    {
      "metadata": {
        "id": "X3noFDaX6w-T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fvWyugXqfBG9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "pc4B2DMUapyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Parte I: Fundamentos de TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "DkwG-wcr6MA2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TensorFlow Básico"
      ]
    },
    {
      "metadata": {
        "id": "cAGIl8BW6PR5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A maior diferença entre TensorFlow e outras bibliotecas computacionais tal como NumPy é que **operações em TensorFlow são simbólicas**.\n",
        "* Isso é um conceito poderoso que permite ao TensorFlow fazer todo tipo de coisa (por exemplo **diferenciação automática**) que não são possíveis em bibliotecas imperativas como o NumPy.\n",
        "* Porém aumenta a complexidade, o que o torna de mais difícil compreenção.\n",
        "\n",
        "Nosso objetivo é de desmistificar TensorFlow e prover algumas diretrizes e boas práticas para um melhor uso do TensorFlow.\n",
        "\n",
        "Vamos iniciar com um simples exemplo, queremos multiplicar duas matrizes randômicas. Primeiramente vejamos a implementação feita em NumPy:"
      ]
    },
    {
      "metadata": {
        "id": "E-EAfEKz6nMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.random.normal(size=[10, 10])\n",
        "y = np.random.normal(size=[10, 10])\n",
        "z = np.dot(x, y)\n",
        "\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ARir4Wjj65zZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora vamos executar o mesmo cálculo porém dessa vez em TensorFlow:\n"
      ]
    },
    {
      "metadata": {
        "id": "vNJdsJGT6OTs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "#\tcriando os tensores (arestas)\n",
        "x = tf.random_normal([10, 10])\n",
        "y = tf.random_normal([10, 10])\n",
        "\n",
        "#\tcriando as operações (nos)\n",
        "z = tf.matmul(x, y)\n",
        "\n",
        "#criando o grafo e executando-lo em uma sesão\n",
        "sess = tf.Session()\n",
        "z_val = sess.run(z)\n",
        "\n",
        "print(z_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zH5mz37q7eNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Observação:\n",
        "* `NumPy`: imediatamente executa o cálculo e gera o resultado,\n",
        "* `TensorFlow`:  Nos dá somente um identificador (do tipo Tensor) para um nó no gráfico que representa o resultado.\n",
        "\n",
        "Se tentarmos escrever o valor de z diretamente, teremos algo do tipo:\n"
      ]
    },
    {
      "metadata": {
        "id": "asRM6Bdn6KZE",
        "colab_type": "code",
        "outputId": "067eb974-9fa9-4eed-d809-91697ee18180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "#\tcriando os tensores\n",
        "x = tf.random_normal([10, 10])\n",
        "y = tf.random_normal([10, 10])\n",
        "\n",
        "#\tcriando as operações\n",
        "z = tf.matmul(x, y)\n",
        "\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MatMul:0\", shape=(10, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RQieTUBc8Dbv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uma vez que ambas as entradas têm um formato definido, TensorFlow é capaz de inferir o formato do tensor de saída, assim como seu tipo.\n",
        "\n",
        "A fim de computar o valor do tensor, faz-se necessário criar uma sessão e avaliá-la usando o método `Session.run()` .\n"
      ]
    },
    {
      "metadata": {
        "id": "k3lQ4uk9876e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Dica**: Caso esteja utilizando `Jupyter notebook` assegure-se de chamar `tf.reset_default_graph()` no começo para limpar o gráfico simbólico antes de definir novos nós.\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "c9MUyvwu9SyN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para entendermos quão poderoso computação simbólica pode ser vajemos um outro exemplo.\n",
        "\n",
        "1. Assuma que tenhamos amostras de uma curva (digamos $f(x) = 5x^2 + 3$) e queremos estimar $f(x)$ baseado nessas amostras.\n",
        "1. Definimos a função paramétricas $g(x, w) = w_0 x^2 + w_1 x + w_2$, que esta em função de $x$ e parâmetros $w$, nosso objetivo é encontrar os parâmetros tal que $g(x, w) ≈ f(x)$.\n",
        "1. Isso pode ser feito minimizando a seguinte função de perda $L(w) = \\sum(f(x) - g(x, w))^2$. \n",
        "\n",
        "Apesar de que haja uma solução fechada para este simples problema, optamos por utilizar uma aproximação mais generalizada, que pode ser aplicada a qualquer função diferencial arbitrária utilizando-se do gradiente descendente estocástico.\n",
        "Simplesmente calcula-se o gradiente médio de $L(w)$ com relação a $w$ em um conjunto de amostras e move-se na direção oposta.\n",
        "\n",
        "O código em `TensorFlow` ficaria assim: \n"
      ]
    },
    {
      "metadata": {
        "id": "kADU4GQc-FH4",
        "colab_type": "code",
        "outputId": "95b7b72d-47c2-441f-c20c-14e124972c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Placeholders are used to feed values from python to TensorFlow ops. We define\n",
        "# two placeholders, one for input feature x, and one for output y.\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "\n",
        "# Assuming we know that the desired function is a polynomial of 2nd degree, we\n",
        "# allocate a vector of size 3 to hold the coefficients. The variable will be\n",
        "# automatically initialized with random noise.\n",
        "w = tf.get_variable(\"w\", shape=[3, 1])\n",
        "\n",
        "# We define yhat to be our estimate of y.\n",
        "f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1)\n",
        "yhat = tf.squeeze(tf.matmul(f, w), 1)\n",
        "\n",
        "# The loss is defined to be the l2 distance between our estimate of y and its\n",
        "# true value. We also added a shrinkage term, to ensure the resulting weights\n",
        "# would be small.\n",
        "loss = tf.nn.l2_loss(yhat - y) + 0.1 * tf.nn.l2_loss(w)\n",
        "\n",
        "# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.\n",
        "train_op = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
        "\n",
        "def generate_data():\n",
        "    x_val = np.random.uniform(-10.0, 10.0, size=100)\n",
        "    y_val = 5 * np.square(x_val) + 3\n",
        "    return x_val, y_val\n",
        "\n",
        "sess = tf.Session()\n",
        "# Since we are using variables we first need to initialize them.\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for _ in range(1000):\n",
        "    x_val, y_val = generate_data()\n",
        "    _, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})\n",
        "    #print(loss_val)\n",
        "\n",
        "w_val = sess.run([w])\n",
        "print('w = ',w_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('w = ', [array([[ 4.9922128e+00],\n",
            "       [-3.5868271e-04],\n",
            "       [ 3.4673905e+00]], dtype=float32)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3gUOlZXZ_C-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O resultado é uma aproximação relativamente próxima dos nossos parâmetros. \n",
        "\n",
        "Essa é somente a ponta do iceberg que TensorFlow pode fazer.\n",
        "Muitos problemas tais como *otimizar uma grande rede neural* com milhões de parâmetros pode ser implementada de maneira eficiente em Tensorflow em poucas linhas de código.\n",
        "TensorFlow encarrega-se do dimensionamento de vários dispositivos, threads e suporta uma variedade de plataformas."
      ]
    },
    {
      "metadata": {
        "id": "8D1D5gnw_V-j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Entendendo formatos estáticos e dinâmicos"
      ]
    },
    {
      "metadata": {
        "id": "Cw6rWYWr_g1_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tensores em TensorFlow apresenta **atributo de forma estática** que é **determinada durante a contrução do gráfico**.\n",
        "A forma estática poderá ser subespecificada. Por exemplo. pode-se definir um forma do tensor como `[None, 128]`:"
      ]
    },
    {
      "metadata": {
        "id": "9odqVOFQ_6jl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.placeholder(tf.float32, [None, 128])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2VXSEfzj_-k2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Isso significa que\n",
        "* a primeira dimensão pode ser de qualquer tamanho e será determinada dinamicamente durante a `Session.run()`.\n",
        "\n",
        "Pode-se consultar o formato estático do Tensor da seguinte maneira:\n"
      ]
    },
    {
      "metadata": {
        "id": "Zx9ndR1VVPj4",
        "colab_type": "code",
        "outputId": "72cd97c2-8653-46c8-ee84-5a572754d199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "static_shape = a.shape.as_list()  # returns [None, 128]\n",
        "print('static_shape = ',static_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('static_shape = ', [32, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w73AfGxeVpbJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para obter o formato dinâmico do tensor pode-se chamar `tf.shape`, que retorna um tensor representando o formato do tensor dado:"
      ]
    },
    {
      "metadata": {
        "id": "a8--kFyYVtlR",
        "colab_type": "code",
        "outputId": "42b74a6e-3c68-44eb-ea12-9288dcfd73d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dynamic_shape = tf.shape(a)\n",
        "print('dynamic_shape = ',dynamic_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('dynamic_shape = ', <tf.Tensor 'Shape:0' shape=(2,) dtype=int32>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pwa7MFa8V-NY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O formato estático de um tensor pode ser definido com o método `Tensor.set_shape()`:"
      ]
    },
    {
      "metadata": {
        "id": "i587DtVZWC6g",
        "colab_type": "code",
        "outputId": "edec60bf-6679-4e28-bb9a-f2e957f9c633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "a.set_shape([32, 128])  # static shape of a is [32, 128]\n",
        "print('static_shape1 = ',a.shape.as_list())\n",
        "a.set_shape([None, 128])  # first dimension of a is determined dynamically\n",
        "print('static_shape2 = ',a.shape.as_list())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('static_shape1 = ', [32, 128])\n",
            "('static_shape2 = ', [32, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D8mcqpHnW6IA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pode-se modificar um dado tensor dinamicamente usando `tf.reshape` function:"
      ]
    },
    {
      "metadata": {
        "id": "aZWF6stcW9oD",
        "colab_type": "code",
        "outputId": "c8efee31-130a-48a4-dc06-f16385c1e181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('a_shape = ',a.shape.as_list())\n",
        "a =  tf.reshape(a, [128, 32])\n",
        "print('a_shape = ',a.shape.as_list())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('a_shape = ', [32, 128])\n",
            "('a_shape = ', [128, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mMU5QeASXXG2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pode ser conveniente ter uma função que retorna o formato estático quando disponível, caso contrário retorne o formato dinâmico. A função utilidade abaixo faz exatamente isso:"
      ]
    },
    {
      "metadata": {
        "id": "ObKyke80XciB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_shape(tensor):\n",
        "  static_shape = tensor.shape.as_list()\n",
        "  dynamic_shape = tf.unstack(tf.shape(tensor))\n",
        "  dims = [s[1] if s[0] is None else s[0] for s in zip(static_shape, dynamic_shape)]\n",
        "  return dims"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0QlzMD9eXmb_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imaginemos que se queira converter um Tensor de dimensão 3 para um um de dimensão 2 colapsando a segunda e terceira dimensão em uma. Pode-se utilizar  a função `get_shape()` para fazê-lo:"
      ]
    },
    {
      "metadata": {
        "id": "TRTJOy1nXuoY",
        "colab_type": "code",
        "outputId": "cf276d21-097b-47c1-e78c-3720a0f88f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "b = tf.placeholder(tf.float32, [None, 10, 32])\n",
        "shape = get_shape(b)\n",
        "print('shape_before = ',get_shape(b))\n",
        "b = tf.reshape(b, [shape[0], shape[1] * shape[2]])\n",
        "print('shape_after = ',get_shape(b))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('shape_before = ', [<tf.Tensor 'unstack_2:0' shape=() dtype=int32>, 10, 32])\n",
            "('shape_after = ', [<tf.Tensor 'unstack_3:0' shape=() dtype=int32>, 320])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "keyQsDVxYloj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note que isso funciona independente se o formato é estaticamente especificado ou não.\n",
        "\n",
        "Pode-se escrever uma função de redimensionamento de propósito geral para colapsar qualquer lista de qualquer dimensão:"
      ]
    },
    {
      "metadata": {
        "id": "le7l8dL2YnNI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reshape(tensor, dims_list):\n",
        "  shape = get_shape(tensor)\n",
        "  dims_prod = []\n",
        "  for dims in dims_list:\n",
        "    if isinstance(dims, int):\n",
        "      dims_prod.append(shape[dims])\n",
        "    elif all([isinstance(shape[d], int) for d in dims]):\n",
        "      dims_prod.append(np.prod([shape[d] for d in dims]))\n",
        "    else:\n",
        "      dims_prod.append(tf.prod([shape[d] for d in dims]))\n",
        "  tensor = tf.reshape(tensor, dims_prod)\n",
        "  return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehCSJSkgZQao",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora colapsar a segunda dimensão torna-se muito fácil:"
      ]
    },
    {
      "metadata": {
        "id": "OvtkCjxhZS2h",
        "colab_type": "code",
        "outputId": "56fb485d-c810-416f-e4a5-0160f0b190e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "b = tf.placeholder(tf.float32, [None, 10, 32])\n",
        "print('shape_before = ',get_shape(b))\n",
        "b = reshape(b, [0, [1, 2]])\n",
        "print('shape_after = ',get_shape(b))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('shape_before = ', [<tf.Tensor 'unstack_4:0' shape=() dtype=int32>, 10, 32])\n",
            "('shape_after = ', [<tf.Tensor 'unstack_6:0' shape=() dtype=int32>, 320])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "levKQctTZp0C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Escopos e quando utilizá-los"
      ]
    },
    {
      "metadata": {
        "id": "ZbN6ixG0Z1No",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Variáveis e tensores em TensorFlow tem o atributo nome que é usado para identificá-los no gráfico simbólico.\n",
        "\n",
        "Caso não seja especificado o nome quando se cria uma variável ou tensor, TensorFlow automaticamente designa um nome:"
      ]
    },
    {
      "metadata": {
        "id": "hlnHdaA2Z8zc",
        "colab_type": "code",
        "outputId": "1efebed3-3cf7-4e7a-c563-3274a1743a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(1)\n",
        "print(a.name)  \n",
        "b = tf.Variable(1)\n",
        "print(b.name)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Const_2:0\n",
            "Variable_2:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7dSzBz4iaokE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pode-se sobrescrever o nome *defaulf* especificando explicitamente o nome:"
      ]
    },
    {
      "metadata": {
        "id": "S8ZmmsdGasKi",
        "colab_type": "code",
        "outputId": "ea59c6a3-c2b8-4568-93b3-9245efdbb752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(1, name=\"a\")\n",
        "print(a.name)  \n",
        "b = tf.Variable(1, name=\"b\")\n",
        "print(b.name)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a:0\n",
            "b:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hFQL96Mla7Yu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow tem duas maneiras de modificar o nome dos tensores e variáveis. O primeiro é `tf.name_scope`:"
      ]
    },
    {
      "metadata": {
        "id": "14mB1VxYaGXL",
        "colab_type": "code",
        "outputId": "51ca9b35-cb9c-4f0b-bfaf-d0029027bda9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.name_scope(\"scope\"):\n",
        "  a = tf.constant(1, name=\"a\")\n",
        "  print(a.name)  \n",
        "  \n",
        "  b = tf.Variable(1, name=\"b\")\n",
        "  print(b.name)  \n",
        "\n",
        "  c = tf.get_variable(name=\"c\", shape=[])\n",
        "  print(c.name)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scope/a:0\n",
            "scope/b:0\n",
            "c:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9f6COMEP1ql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note que há duas maneiras de definir uma nova variável em TensorFlow criando-se um objeto `tf.Variable` ou a partir de `tf.get_variable`.\n",
        "* Utilizando-se de `tf.get_variable` com um novo nome resulta em criar uma uma nova variável, porém se a variável com o mesmo nome existir resultará em uma exceção *ValueError*, dizendo que redeclarar uma variável não é permitido.\n",
        "* `tf.name_scope` afeta o nome de tensores e variáveis criadas com `tf.Variable`, porém não impacta as variáveis criadas com `tf.get_variable`.\n",
        "\n",
        "Diferentemente de `tf.name_scope`, `tf.variable_scope` modifica o nome da variável criada também com `tf.get_variable`:"
      ]
    },
    {
      "metadata": {
        "id": "hleqsnhGQ7rA",
        "colab_type": "code",
        "outputId": "89243093-49d2-41fe-b4bc-c1e5c26dfd27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"scope\"):\n",
        "  a = tf.constant(1, name=\"a\")\n",
        "  print(a.name)  # prints \"scope/a:0\"\n",
        "\n",
        "  b = tf.Variable(1, name=\"b\")\n",
        "  print(b.name)  # prints \"scope/b:0\"\n",
        "\n",
        "  c = tf.get_variable(name=\"c\", shape=[])\n",
        "  print(c.name)  # prints \"scope/c:0\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scope/a:0\n",
            "scope/b:0\n",
            "scope/c:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mGy_62AKRIYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"scope\"):\n",
        "  a1 = tf.get_variable(name=\"a\", shape=[])\n",
        "  a2 = tf.get_variable(name=\"a\", shape=[])  # Disallowed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "poQYlXN1RRYm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mas e se quisessemos reutilizar uma variável previamente declarada? `tf.variable_scope` também apresenta uma funcionalidade para fazê-lo:"
      ]
    },
    {
      "metadata": {
        "id": "02kcA-dIRSLZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"scope\"):\n",
        "  a1 = tf.get_variable(name=\"a\", shape=[])\n",
        "with tf.variable_scope(\"scope\", reuse=True):\n",
        "  a2 = tf.get_variable(name=\"a\", shape=[])  # OK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WH7AkxG_Rg3m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Isso se faz útil por exemplo quando se utiliza camadas de redes neurais integradas:"
      ]
    },
    {
      "metadata": {
        "id": "UNvnKEEfRkqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope('my_scope'):\n",
        "  features1 = tf.layers.conv2d(image1, filters=32, kernel_size=3)\n",
        "# Use the same convolution weights to process the second image:\n",
        "with tf.variable_scope('my_scope', reuse=True):\n",
        "  features2 = tf.layers.conv2d(image2, filters=32, kernel_size=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mw2dsyDuRv4m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Alternativamente pode-se usar reuse para tf.AUTO_REUSE que diz ao TensorFlow para criarr uma nova variável se uma variável co mesmo nome não existir, caso contrário reutilizá-la:"
      ]
    },
    {
      "metadata": {
        "id": "oTVTW1nnR-ui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.variable_scope(\"scope\", reuse=tf.AUTO_REUSE):\n",
        "  features1 = tf.layers.conv2d(image1, filters=32, kernel_size=3)\n",
        "  features2 = tf.layers.conv2d(image2, filters=32, kernel_size=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbVI3muESDQn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Caso queira-se fazer muitos compartilhamento de variáveis mantendo-se o controle de quando definir novas variáveis e quando reutiliza-las então pode ser complicado e sujeito a erros.\n",
        "`tf.AUTO_REUSE` simplifica a tarefa porém adiciona o risco de compartilhar variáveis que supostamente não deveriam ser compartilhadas. O *template* do TensorFlow é outra maneira de resolver o mesmo problema sem tal risco:"
      ]
    },
    {
      "metadata": {
        "id": "EIkigaRxSMdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conv3x32 = tf.make_template(\"conv3x32\", lambda x: tf.layers.conv2d(x, 32, 3))\n",
        "features1 = conv3x32(image1)\n",
        "features2 = conv3x32(image2)  # Will reuse the convolution weights."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PP_c0dDoSR8R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pode-se tornar qualquer função em um *template* do TensorFlow. Na primeira chamada para um *template*, as variáveis definidas dentro da função seriam declaradas e nas chamadas subsequentes seriam automaticamente reutilizadas."
      ]
    },
    {
      "metadata": {
        "id": "3Tow2ZH-SWp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Difusão: Pontos fortes e fracos\n",
        "\n",
        "TensorFlow suporta a difusão de operações elemento a elemento.\n",
        "Normalmente quando se deseja fazer operações como adição ou multiplicação, é necessário certificar-se que as dimensões dos operandos estajam de acordo, por exemplo, não se pode adicionar um tensor de dimensão `[3,2]` com um tensor `[3,4]`.\n",
        "Porém há uma excessão, caso se tem somente uma dimensão.\n",
        "TensorFlow implicitamente organiza os tensores em uma dimensão para que o formato seja igual ao do outro operando.\n",
        "Portanto é aceitável adicionar um tensor de dimensão `[3, 2]` com um tensor de dimensão `[3, 1]`."
      ]
    },
    {
      "metadata": {
        "id": "5a36dqKxSwNb",
        "colab_type": "code",
        "outputId": "ee6c838d-c368-424a-d750-4a4ee6723e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1., 2.], [3., 4.]])\n",
        "b = tf.constant([[1.], [2.]])\n",
        "# c = a + tf.tile(b, [1, 2])\n",
        "c = a + b\n",
        "with tf.Session() as session:\n",
        "  result  = session.run(c)  #result = v.eval() #forma equivalente\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2. 3.]\n",
            " [5. 6.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BDO-58__TafF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Difusão nos permite agrupar implicitamente, o que torna o código menor, e mais eficiente em relação à memória, uma vez que não é necessário guardar o resultado da operação de agrupamento.\n",
        "Um lugar onde pode ser facilmente implementado é ao combinar *features* de tamanhos distintos.\n",
        "A fim de concatenar *features* de tamanhos diferentes normalmente agrupa-se os tensores de entrada, concatena o resultado e aplica-se alguma não-linearidade.\n",
        "**Esse é um procedimento padrão entre várias arquiteturas de redes neurais**."
      ]
    },
    {
      "metadata": {
        "id": "Q7uzykmTTzdr",
        "colab_type": "code",
        "outputId": "e7afed65-74ff-4090-8896-5b6ba0a2c60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.random_uniform([5, 3, 5])\n",
        "b = tf.random_uniform([5, 1, 6])\n",
        "\n",
        "# concat a and b and apply nonlinearity\n",
        "tiled_b = tf.tile(b, [1, 3, 1])\n",
        "c = tf.concat([a, tiled_b], 2)\n",
        "d = tf.layers.dense(c, 10, activation=tf.nn.relu)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  #print(session.run(tiled_b))\n",
        "  print(session.run(c))\n",
        "  #print(session.run(d)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.6937026  0.15428507 0.2800038  0.08377886 0.12188792 0.5092124\n",
            "   0.695078   0.4601586  0.82269514 0.7481663  0.7347907 ]\n",
            "  [0.16978633 0.36053598 0.16227639 0.7982862  0.6463525  0.5092124\n",
            "   0.695078   0.4601586  0.82269514 0.7481663  0.7347907 ]\n",
            "  [0.6232879  0.43789756 0.80180585 0.6007143  0.54549825 0.5092124\n",
            "   0.695078   0.4601586  0.82269514 0.7481663  0.7347907 ]]\n",
            "\n",
            " [[0.22090471 0.31535435 0.5629263  0.3793478  0.60918427 0.68534255\n",
            "   0.6267303  0.71711516 0.5630053  0.6170057  0.5886011 ]\n",
            "  [0.5502802  0.55038464 0.07872856 0.8033217  0.83834624 0.68534255\n",
            "   0.6267303  0.71711516 0.5630053  0.6170057  0.5886011 ]\n",
            "  [0.4749012  0.43129456 0.61200035 0.7015667  0.90547967 0.68534255\n",
            "   0.6267303  0.71711516 0.5630053  0.6170057  0.5886011 ]]\n",
            "\n",
            " [[0.51492727 0.49063408 0.6472235  0.42694485 0.9332788  0.94186914\n",
            "   0.09389567 0.76210356 0.00971448 0.85871506 0.03518164]\n",
            "  [0.0576483  0.06008446 0.15991223 0.6457871  0.30569184 0.94186914\n",
            "   0.09389567 0.76210356 0.00971448 0.85871506 0.03518164]\n",
            "  [0.7202405  0.23647058 0.6942618  0.62667763 0.4135698  0.94186914\n",
            "   0.09389567 0.76210356 0.00971448 0.85871506 0.03518164]]\n",
            "\n",
            " [[0.17352045 0.14470255 0.1059376  0.46654844 0.48657966 0.4362011\n",
            "   0.90611553 0.76159    0.47261274 0.36685407 0.7907051 ]\n",
            "  [0.5611588  0.10189164 0.53168106 0.3823582  0.95938146 0.4362011\n",
            "   0.90611553 0.76159    0.47261274 0.36685407 0.7907051 ]\n",
            "  [0.5209532  0.5431979  0.327083   0.95845103 0.13369536 0.4362011\n",
            "   0.90611553 0.76159    0.47261274 0.36685407 0.7907051 ]]\n",
            "\n",
            " [[0.27793443 0.02233255 0.59707713 0.54039264 0.4431789  0.418213\n",
            "   0.234949   0.6185926  0.31132996 0.88933694 0.9839337 ]\n",
            "  [0.8138777  0.42909408 0.63658106 0.52854526 0.68817234 0.418213\n",
            "   0.234949   0.6185926  0.31132996 0.88933694 0.9839337 ]\n",
            "  [0.2202568  0.55266035 0.5153638  0.01934719 0.3002057  0.418213\n",
            "   0.234949   0.6185926  0.31132996 0.88933694 0.9839337 ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RLBIIa8jU_wR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Porém isso pode ser feito de maneira mais eficiente com uso de difusão. Usa-se o fato de que `f(m(x+y))` é igual a `f(mx+my)`.\n",
        "Por fim pode-se fazer operações lineares separadamente utilizando a difusão para fazer concatenação implícita:"
      ]
    },
    {
      "metadata": {
        "id": "EP4Gw_cPVJIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pa = tf.layers.dense(a, 10, activation=None)\n",
        "pb = tf.layers.dense(b, 10, activation=None)\n",
        "d = tf.nn.relu(pa + pb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "chNihSErVQb5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Na verdade essa parte do código é bastante generalista e pode ser aplicada a tensores de dimensões arbitrárias contanto que seja possível fazer a difusão entre tensores:"
      ]
    },
    {
      "metadata": {
        "id": "7TEPIAhOVTPs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def merge(a, b, units, activation=tf.nn.relu):\n",
        "    pa = tf.layers.dense(a, units, activation=None)\n",
        "    pb = tf.layers.dense(b, units, activation=None)\n",
        "    c = pa + pb\n",
        "    if activation is not None:\n",
        "        c = activation(c)\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OooL2nfCVX67",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uma forma mais generalista dessa função pode ser encontrada neste [livro](https://github.com/vahidk/EffectiveTensorflow#merge) (livro em inglês).\n",
        "\n",
        "Até o momento discutiu-se o lado bom da difusão. Porém quais problemas existem?\n",
        "Suposições implícitas quase sempre torna difícil debugar. Considere o exemplo abaixo:"
      ]
    },
    {
      "metadata": {
        "id": "Eyn-uKZ-VkdU",
        "colab_type": "code",
        "outputId": "280a0ef8-b8ef-40fe-cd10-f594050f684f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1.], [2.]])\n",
        "b = tf.constant([1., 2.])\n",
        "c = tf.reduce_sum(a + b)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  print(session.run(c))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "--Yx3u2iVwc0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Qual você pensaria que seria o valor de `c`?\n",
        "Se você disse `6` você está errado.\n",
        "Será `12`.\n",
        "Isso porque quando o *rank* de dois tensores não combinam, **TensorFlow automaticamente expande a primeira dimensão do tensor de menor rank antes de fazer a operação elemento a elemento**, portanto o resultado da adição seria `[[2,3],[3,4]]`, e a redução de todos os parâmetros daria 12.\n",
        "\n",
        "**A maneira de evitar esse problema é ser tão explícito quanto se poda**.\n",
        "Case houvessemos especificado qual a dimensão nós gostaríamos de reduzir, encontrar esse bug teria sido muito mais fácil:"
      ]
    },
    {
      "metadata": {
        "id": "Z97KIZEAWGPy",
        "colab_type": "code",
        "outputId": "19d4f62b-d25f-4e82-a2e9-9fe6d0755e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1.], [2.]])\n",
        "b = tf.constant([1., 2.])\n",
        "c = tf.reduce_sum(a + b, 0)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  print(session.run(c))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5. 7.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IZBURmhHWMnd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui o valor de `c` seria `[5,7]`, e nós teríamos adivinhado baseado no formato do resultado que há alguma coisa errada.\n",
        "**Uma regra geral é sempre especificar as dimensões em operação de redução e quando se utiliza `tf.squeeze`.**"
      ]
    },
    {
      "metadata": {
        "id": "rgbhwbhpjm5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importando dados ao TensorFlow\n",
        "\n",
        "O TensorFlow foi desenvolvido para trabalhar de maneira eficiente com grandes quantidades de dados. Portanto é importante não alimentar seu modelo TensorFlow a fim de maximizar sua performance. Existem várias maneiras de alimentar dados ao TensorFlow.\n",
        "\n",
        "TensorFlow is designed to work efficiently with large amount of data. So it's important not to starve your TensorFlow model in order to maximize its performance. There are various ways that you can feed your data to TensorFlow."
      ]
    },
    {
      "metadata": {
        "id": "X8ROH__ojyVG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Constantes**\n",
        "\n",
        "A maneira mais simples é declarar os dados como constantes:"
      ]
    },
    {
      "metadata": {
        "id": "yogam-XZkCrS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "actual_data = np.random.normal(size=[100])\n",
        "\n",
        "data = tf.constant(actual_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SRYVtOYmkFNK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Essa forma pode ser muito eficiente, porém não muito flexível. Um problema é que em ao usar seu modelo com outro dataset deve-se reescrever o grafo. Além de que têm-se que carregar todos os dados na memória de uma vez a mantê-los na memória, o que só funcionaria para pequenos datasets."
      ]
    },
    {
      "metadata": {
        "id": "rgjSdqW7kPYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Espaços reservados (placeholders)**\n",
        "\n",
        "Usar espaços reservadoe resolver ambos os problemas acima citados:"
      ]
    },
    {
      "metadata": {
        "id": "UaYOyUCjkY83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "data = tf.placeholder(tf.float32)\n",
        "\n",
        "prediction = tf.square(data) + 1\n",
        "\n",
        "actual_data = np.random.normal(size=[100])\n",
        "\n",
        "tf.Session().run(prediction, feed_dict={data: actual_data})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VC2PE1XpkbWk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O operador de espaços reservados retora um tensor cujo vajor é capturado a partir do argumento `feed_dict` na função `Session.run`. Note que executar `Session.run` sem alimentar os valores dos dados, neste caso, resultará em erro."
      ]
    },
    {
      "metadata": {
        "id": "_tcnNGfzkdj8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Python ops**\n",
        "\n",
        "Outra maneira de alimentar dados ao TensorFlow é utilizando *Python ops*:\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "HUJM8bWbkjW-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def py_input_fn():\n",
        "    actual_data = np.random.normal(size=[100])\n",
        "    return actual_data\n",
        "\n",
        "data = tf.py_func(py_input_fn, [], (tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IrbEeZ2LklS_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*Python ops* permite converter uma função Python normal em uma operação em TensorFlow."
      ]
    },
    {
      "metadata": {
        "id": "7mA3ndzFkm_6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dataset API**\n",
        "\n",
        "A forma recomendada de ler dados em TensorFlow é utilizando **dataset API**:"
      ]
    },
    {
      "metadata": {
        "id": "cGXTiKIxkuI4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "actual_data = np.random.normal(size=[100])\n",
        "dataset = tf.contrib.data.Dataset.from_tensor_slices(actual_data)\n",
        "data = dataset.make_one_shot_iterator().get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DIrP5Zmkv6G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Caso você tenha que ler seus dados a partir de um arquivo pode ser mais eficiente escrever no formato `TFrecord` e utilizar `TFRecordDataset` para ler:"
      ]
    },
    {
      "metadata": {
        "id": "CjY_WuFVkyf_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = tf.contrib.data.TFRecordDataset(path_to_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pvpteneik3nn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Veja os documentos oficiais para um exemplo de como escrever os dados em formato `TFrecord`.\n",
        "\n",
        "Dataset API permite que você faça processamento eficiente de dados usando pipelines de maneira fácil. Por exemplo, assim processamos nossos dados no código abaixo: [trainer.py](https://github.com/vahidk/TensorflowFramework/blob/master/trainer.py):"
      ]
    },
    {
      "metadata": {
        "id": "BTDK5ochlA2d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = ...\n",
        "dataset = dataset.cache()\n",
        "if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(batch_size * 5)\n",
        "dataset = dataset.map(parse, num_threads=8)\n",
        "dataset = dataset.batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QZfxmNmlDMg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Após ler os dados, utilizamos o método `Dataset.cache` para armazenar-lo em memória a fim de aumentar a eficiência. Durante o modo de treino, repetimos o dataset indefinidamente. Isso permite processar todo o dataset muitas vezes. Nós embaralhamos o dataset para pegar *batches* com diferentes distribuições de dados. Após utiliza-se a função `Dataset.map` para fazer o pré-processamento em registros brutos e converter os dados a um formato utilizável pelo modelo. Por fim cria-se os *batches* de amostras chamando `Dataset.batch`."
      ]
    },
    {
      "metadata": {
        "id": "WT3UPmmDlLJm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Tire vantagens da sobrecarga de operadores\n",
        "\n",
        "Assim como NumPy, TensorFlow sobrecarrega um número de operadores Python para facilitar a construção de grafos e tornar o código mais fácil de ler.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8J4ZfvFqlTX2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A operação de repartição é um dos operadores que pode facilitar a indexação de tensores:"
      ]
    },
    {
      "metadata": {
        "id": "QFLs1fm8lUVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = x[begin:end]  # z = tf.slice(x, [begin], [end-begin])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "evg5h4DblWEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Porém há de ser cuidadoso ao utilizar a operação de repartição. A operação de repartição é bastante ineficiente e melhor se evitada, especialmente quando o número de repartições é alto. Para entender quão ineficiente tal operação pode ser  vejamos um exemplo. Queremos manualmente fazer uma redução através as linhas da matriz:"
      ]
    },
    {
      "metadata": {
        "id": "Cqyc30unlaov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "x = tf.random_uniform([500, 10])\n",
        "\n",
        "z = tf.zeros([10])\n",
        "for i in range(500):\n",
        "    z += x[i]\n",
        "\n",
        "sess = tf.Session()\n",
        "start = time.time()\n",
        "sess.run(z)\n",
        "print(\"Took %f seconds.\" % (time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1PrZrl_SldC-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Em um MacBook Pro, essa operação demorou 2.67 segundos para rodar. a razão disso é que se está chamando a operação 500 vezes, o que tornará o código bastante lento para rodar. Uma melhor alternatica seria usar a opreração `tf.unstack` para separar a matriz em uma lista de vetores de uma só vez:"
      ]
    },
    {
      "metadata": {
        "id": "Iyo8pqclldy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = tf.zeros([10])\n",
        "for x_i in tf.unstack(x):\n",
        "    z += x_i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qn3elMaBlgQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Essa operação demorou 0.18 segundos. Com certeza, a maeira correta de fazer essa simples redução é usando a operação `tf.reduce_sum`:"
      ]
    },
    {
      "metadata": {
        "id": "MUtSxfrhlg6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = tf.reduce_sum(x, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5hh0YXCwliWq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dessa forma demorou 0.008 segundos, o que é 300x mais rápido que a implementação original.\n",
        "\n",
        "TensorFlow também sobrecarrega uma gama de operações aritiméticas e lógicas de maneira mais eficiente:"
      ]
    },
    {
      "metadata": {
        "id": "-OOVx2yllkJC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "z = -x  # z = tf.negative(x)\n",
        "z = x + y  # z = tf.add(x, y)\n",
        "z = x - y  # z = tf.subtract(x, y)\n",
        "z = x * y  # z = tf.mul(x, y)\n",
        "z = x / y  # z = tf.div(x, y)\n",
        "z = x // y  # z = tf.floordiv(x, y)\n",
        "z = x % y  # z = tf.mod(x, y)\n",
        "z = x ** y  # z = tf.pow(x, y)\n",
        "z = x @ y  # z = tf.matmul(x, y)\n",
        "z = x > y  # z = tf.greater(x, y)\n",
        "z = x >= y  # z = tf.greater_equal(x, y)\n",
        "z = x < y  # z = tf.less(x, y)\n",
        "z = x <= y  # z = tf.less_equal(x, y)\n",
        "z = abs(x)  # z = tf.abs(x)\n",
        "z = x & y  # z = tf.logical_and(x, y)\n",
        "z = x | y  # z = tf.logical_or(x, y)\n",
        "z = x ^ y  # z = tf.logical_xor(x, y)\n",
        "z = ~x  # z = tf.logical_not(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ie28Y4iQlno_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pode-se também usar as versões aumentadas dessas operações. Por exemplo `x += y` e `x **= 2` também são válidos.\n",
        "\n",
        "Note que Python não permite a sobrecarga das palavras-chave `\"and\"`, `\"or\"` e `\"not\"`. \n",
        "\n",
        "TensorFlow não permite utilizar tensores como booleanos, tal ação pode resultar em erro:"
      ]
    },
    {
      "metadata": {
        "id": "nmjK-3_hly-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant(1.)\n",
        "if x:  # This will raise a TypeError error\n",
        "    ..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z3PHLmOpmMvI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pode-se usar `tf.cond(x,...)` caso queira checar o valor do tensor, ou usar \"`if x is None`\" para checar o valor da variável.\n",
        "\n",
        "Outras operações que não são suportadas é a de igual(==) e de diferente(!=), operadores que são permitidos em NumPy porém não em TensorFlow. Utilize a versão do TensorFlow que são `tf.equal` e `tf.not_equal`."
      ]
    },
    {
      "metadata": {
        "id": "-zffTc5QmUqK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Entendendo a ordem de execução e controle de dependências"
      ]
    },
    {
      "metadata": {
        "id": "ixPUgRV4mZ6Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como discutido no primeiro item, TensorFlow não roda imediatamente operações que são definidas, mas cria nós correspondentes em um grafo que pode ser avaliado com o método `Session.run()`. Isso permite que o TensorFlow faça otimizações no tempo de execução para determinar a ordem de execução ótima e possível corte de nós não utilizados. Caso tenha-se somente `tf.Tensord` no grafo não há necessidade de preocupar-se com dependencias, porém provavelmente existe no código também  `tf.Variables`, o que torna a situação mais complicada. Meu conselho é utilizar Variáveis somente se Tensores não forem suficientes para a tarefa. Talvez isso não faça muito sentido, portanto vamos começar com um exemplo."
      ]
    },
    {
      "metadata": {
        "id": "p0da2yG4mcEX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant(1)\n",
        "b = tf.constant(2)\n",
        "a = a + b\n",
        "\n",
        "tf.Session().run(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W5lY3pFwmdpI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Avaliar \"`a`\" retornará o valor 3 como esperado. Note que criou-se 3 tensores, dois tensores constantes e um tensor para guardar o resultado da adição. Note que não se pode sobrescrever o valor de um tensor. Caso queira-se modificar o valor do tensor tem-se que criar um novo tensor. Como foi feito aqui.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "DICA: Caso você não defina um novo grafo, TensorFlow automaticamente cria um grafo por *default* . Pode-se usar `tf.get_default_graph()` para acessar o grafo. Você pode então inspecionar o grafo, como por exemplo imprimindo todos os tensores:\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "q474iNlKmzzj",
        "colab_type": "code",
        "outputId": "f8d6c002-986f-4bce-b07b-a1323af1dc36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "print(tf.contrib.graph_editor.get_tensors(tf.get_default_graph()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f23664bdb1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_editor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "BsdCstIrm7D3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Diferente de tensores, variáveis podem ser atualizadas. Portanto vejamos como utilizariamos variáveis para fazer a mesma tarefa:"
      ]
    },
    {
      "metadata": {
        "id": "pykVYtuKm8Qq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.Variable(1)\n",
        "b = tf.constant(2)\n",
        "assign = tf.assign(a, a + b)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "print(sess.run(assign))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K73onRotm-WC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Novamente obtem-se 3 como esperado. Note que `tf.assign` retorna um tensor representando o valor atribuido. Até o momento tudo parece bom, porém vejamos um exemplo um pouco mais complicado:"
      ]
    },
    {
      "metadata": {
        "id": "m9htp2FqnEut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.Variable(1)\n",
        "b = tf.constant(2)\n",
        "c = a + b\n",
        "\n",
        "assign = tf.assign(a, 5)\n",
        "\n",
        "sess = tf.Session()\n",
        "for i in range(10):\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run([assign, c]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8i-P93wvnJlU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note que o tensor c não tem um valor determinístico. Esse valor pode ser 3 ou 7 dependendo de qual adição ou atribuição é executada primeiro.\n",
        "\n",
        "Note que a ordem em que se define operações em seu código não importa para a execução do TensorFlow. A única coisa que importa é o controle de dependências. Controle de dependências para tensores é bem direta. Cada vez que utiliza-se um tensor em uma operação, essa operação define uma dependência implícita para aquele tensor. Porém as coisas podem ficar complicadas com variáveis porque elas podem ter vários valores.\n",
        "\n",
        "Quando se esta lidando com variáveis, se faz necessário definir explicitamente as dependências usando `tf.control_dependencies()` como a seguir:"
      ]
    },
    {
      "metadata": {
        "id": "ZzX6wiYmnthU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.Variable(1)\n",
        "b = tf.constant(2)\n",
        "c = a + b\n",
        "\n",
        "with tf.control_dependencies([c]):\n",
        "    assign = tf.assign(a, 5)\n",
        "\n",
        "sess = tf.Session()\n",
        "for i in range(10):\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(sess.run([assign, c]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sSoSFbwsnv1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Assim estará assegurado que a operação `assign` será chamada depois da adição."
      ]
    },
    {
      "metadata": {
        "id": "3pqEMR90xysF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Operações de controle de fluxo: condicionais e loops\n",
        "\n",
        "Ao construir modelos complexos como redes neurais recorrentes, as vezes se faz necessário controlar o fluxo de operações a partir de condicionais e loops. Nesta seção introduzimos as operações mais comumente utilizada para controle de fluxo."
      ]
    },
    {
      "metadata": {
        "id": "F3t6zcnHx_kf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Digamos que você queira decidir se deve multiplicar ou adicionar dois tensores dados baseados em um predicado. Isso pode ser implementado simplesmente com `tf.cond` que atua como o condicional if `if`:"
      ]
    },
    {
      "metadata": {
        "id": "c70Cz8PEyCPg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant(1)\n",
        "b = tf.constant(2)\n",
        "\n",
        "p = tf.constant(True)\n",
        "\n",
        "x = tf.cond(p, lambda: a + b, lambda: a * b)\n",
        "\n",
        "print(tf.Session().run(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qXi-vHgmyIN7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como o predicado é Verdadeiro nesse caso, a saída seria o resultado da adição, que é 3."
      ]
    },
    {
      "metadata": {
        "id": "61FFcSYNyI4w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Na maioria das vezes, quando se usa TensorFlow, utiliza-se grandes tensores e se deseja fazer operações em bateladas. Uma operação condicional relacionada é `tf.where`, que como `tf.cond` recebe um predicado, porém seleciona a saída baseada em uma condição em batelada."
      ]
    },
    {
      "metadata": {
        "id": "iLPYke8ryMf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([1, 1])\n",
        "b = tf.constant([2, 2])\n",
        "\n",
        "p = tf.constant([True, False])\n",
        "\n",
        "x = tf.where(p, a + b, a * b)\n",
        "\n",
        "print(tf.Session().run(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FHpZUEKRyOlE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Isso irá retornar `[3, 2]`."
      ]
    },
    {
      "metadata": {
        "id": "u6t4DCZ7yTYU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Outro método de controle de fluxo bastante utilizado é `tf.while_loop`. Que permite construir um loop dinâmico em TensorFlow, que opera em sequencias de tamanho variável. Vejamos como gerar a sequencia de Fibonacci com `tf.while_loop`:"
      ]
    },
    {
      "metadata": {
        "id": "uCE9CnZsyWTP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = tf.constant(5)\n",
        "\n",
        "def cond(i, a, b):\n",
        "    return i < n\n",
        "\n",
        "def body(i, a, b):\n",
        "    return i + 1, b, a + b\n",
        "\n",
        "i, a, b = tf.while_loop(cond, body, (2, 1, 1))\n",
        "\n",
        "print(tf.Session().run(b))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Po0w0YiTyc92",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Iso irá imprimir 5. `tf.while_loop` recebe uma função condição, e uma função de corpo, em adicão aos valores iniciais para variáveis de *loop*. Essas vairáveis de *loop* são então atualizadas por múltiplas chamadas na função de corpo até que a condição retorne falso.\n",
        "\n",
        "Agora imagine que queiramos manter toda a sequência da série de Fibonacci. Teremos que atualizar o corpo da função para manter o histórico dos valores correntes: "
      ]
    },
    {
      "metadata": {
        "id": "R9bMwKIWyg16",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = tf.constant(5)\n",
        "\n",
        "def cond(i, a, b, c):\n",
        "    return i < n\n",
        "\n",
        "def body(i, a, b, c):\n",
        "    return i + 1, b, a + b, tf.concat([c, [a + b]], 0)\n",
        "\n",
        "i, a, b, c = tf.while_loop(cond, body, (2, 1, 1, tf.constant([1, 1])))\n",
        "\n",
        "print(tf.Session().run(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xg5vY8fiyh0X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora se tentarmos rodar esse código o TensorFlow irá reclamar que o formato da quarta variável  loop está mudando. Portanto deve-se explicitar que a mudança é intencional:"
      ]
    },
    {
      "metadata": {
        "id": "PEuVk8EUymBh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i, a, b, c = tf.while_loop(\n",
        "    cond, body, (2, 1, 1, tf.constant([1, 1])),\n",
        "    shape_invariants=(tf.TensorShape([]),\n",
        "                      tf.TensorShape([]),\n",
        "                      tf.TensorShape([]),\n",
        "                      tf.TensorShape([None])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "10RlvtteyoMH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Isso não está somente ficando feio, mas também ineficiente. Note que estamos construindo um monte de tensores intermediários que não utilizamos. TensorFlow tem uma  melhor forma de solucionar esse tipo de arrays crescentes. Conheça `tf.TensorArray`. Façamos a mesma coisa, porém dessa vez com vetores de tensor:"
      ]
    },
    {
      "metadata": {
        "id": "MOy14M_6yrH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n = tf.constant(5)\n",
        "\n",
        "c = tf.TensorArray(tf.int32, n)\n",
        "c = c.write(0, 1)\n",
        "c = c.write(1, 1)\n",
        "\n",
        "def cond(i, a, b, c):\n",
        "    return i < n\n",
        "\n",
        "def body(i, a, b, c):\n",
        "    c = c.write(i, a + b)\n",
        "    return i + 1, b, a + b, c\n",
        "\n",
        "i, a, b, c = tf.while_loop(cond, body, (2, 1, 1, c))\n",
        "\n",
        "c = c.stack()\n",
        "\n",
        "print(tf.Session().run(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oUgeansnywGF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*While loops* e vetores de tensor do TensorFlow são ferramentas essenciais para construir Redes neurais recorrentes complexas. Como exercício tente implementar [*beam search*](https://en.wikipedia.org/wiki/Beam_search) usando `tf.while_loop`. Você pode fazê-lo mais eficientemente com vetores de tensor?\n"
      ]
    },
    {
      "metadata": {
        "id": "AlIS2ic8lTH_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Prototipando kernels e visualizações avançadas com operações Python\n",
        "\n",
        "Operações de kernel em TensorFlow são escritos inteiramente em C++ pela sua eficiência. Porém escrever um TensorFlow kernel em C++ pode ser bastante doloroso. Portanto, antes de passar horas implementando seu kernel, você pode querer prototipar algo rapidamente, porém de maneira ineficiente. Com `tf.py_func()` você pode transformar qualquer parte de código python em uma operação de TensorFlow."
      ]
    },
    {
      "metadata": {
        "id": "-5jCktzhlY8-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Por exemplo, assim pode-se implementar uma simples kernel de não linearidade ReLU em TensorFlowem python:"
      ]
    },
    {
      "metadata": {
        "id": "Iz152UbglcYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import uuid\n",
        "\n",
        "def relu(inputs):\n",
        "    # Define the op in python\n",
        "    def _relu(x):\n",
        "        return np.maximum(x, 0.)\n",
        "\n",
        "    # Define the op's gradient in python\n",
        "    def _relu_grad(x):\n",
        "        return np.float32(x > 0)\n",
        "\n",
        "    # An adapter that defines a gradient op compatible with TensorFlow\n",
        "    def _relu_grad_op(op, grad):\n",
        "        x = op.inputs[0]\n",
        "        x_grad = grad * tf.py_func(_relu_grad, [x], tf.float32)\n",
        "        return x_grad\n",
        "\n",
        "    # Register the gradient with a unique id\n",
        "    grad_name = \"MyReluGrad_\" + str(uuid.uuid4())\n",
        "    tf.RegisterGradient(grad_name)(_relu_grad_op)\n",
        "\n",
        "    # Override the gradient of the custom op\n",
        "    g = tf.get_default_graph()\n",
        "    with g.gradient_override_map({\"PyFunc\": grad_name}):\n",
        "        output = tf.py_func(_relu, [inputs], tf.float32)\n",
        "    return output\n",
        "\n",
        "To verify that the gradients are correct you can use TensorFlow's gradient checker:\n",
        "\n",
        "x = tf.random_normal([10])\n",
        "y = relu(x * x)\n",
        "\n",
        "with tf.Session():\n",
        "    diff = tf.test.compute_gradient_error(x, [10], y, [10])\n",
        "    print(diff)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b0AYsYHXldm5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`compute_gradient_error()` calcula o gradiente numericamente e retorna a diferença entre o gradiente provido. O que se busca é uma diferença muito pequena.\n",
        "\n",
        "Note que essa é uma implementação bastante ineficiente, e é utilizável somente para prototipagem, uma vez que código Python não é paralelizável e não irá rodar na GPU. Uma vez verificada a ideia, você definitivamente irá querer escrevê-la como um kernel em C++.\n",
        "\n",
        "Na prática utilizamos operações em python para vizualização no Tensorboard. Considere o caso em que você esteja construindo um modelo de classificador de imagem e queira vizualizar as predições do modelo durante o treinamento. TensorFlow permite visualizar imagens com a função `tf.summary.image()`:"
      ]
    },
    {
      "metadata": {
        "id": "n-7PvVnglgN5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = tf.placeholder(tf.float32)\n",
        "tf.summary.image(\"image\", image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2_rmE6WIliQW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Porém visualiza-se comente a imagem de entrada. Para que se possa visualizar a predição, tem-se que encontrar uma maneira de adicionar anotações às imagens, o que pode ser quase impossível com as operações existentes. Uma maneira mais fácil de fazê-lo é fazendo o desenho em python, e envolve-lo com uma operação python:"
      ]
    },
    {
      "metadata": {
        "id": "EKFR2QKRlkpf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "def visualize_labeled_images(images, labels, max_outputs=3, name=\"image\"):\n",
        "    def _visualize_image(image, label):\n",
        "        # Do the actual drawing in python\n",
        "        fig = plt.figure(figsize=(3, 3), dpi=80)\n",
        "        ax = fig.add_subplot(111)\n",
        "        ax.imshow(image[::-1,...])\n",
        "        ax.text(0, 0, str(label),\n",
        "          horizontalalignment=\"left\",\n",
        "          verticalalignment=\"top\")\n",
        "        fig.canvas.draw()\n",
        "\n",
        "        # Write the plot as a memory file.\n",
        "        buf = io.BytesIO()\n",
        "        data = fig.savefig(buf, format=\"png\")\n",
        "        buf.seek(0)\n",
        "\n",
        "        # Read the image and convert to numpy array\n",
        "        img = PIL.Image.open(buf)\n",
        "        return np.array(img.getdata()).reshape(img.size[0], img.size[1], -1)\n",
        "\n",
        "    def _visualize_images(images, labels):\n",
        "        # Only display the given number of examples in the batch\n",
        "        outputs = []\n",
        "        for i in range(max_outputs):\n",
        "            output = _visualize_image(images[i], labels[i])\n",
        "            outputs.append(output)\n",
        "        return np.array(outputs, dtype=np.uint8)\n",
        "\n",
        "    # Run the python op.\n",
        "    figs = tf.py_func(_visualize_images, [images, labels], tf.uint8)\n",
        "    return tf.summary.image(name, figs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "No0Dt0_Tlmqp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nopte que uma vez que o sumário são somente avaliados de vez em quando (não a cada passo), essa implementação pode ser usada em pretica sem se preocupar com a eficiência."
      ]
    },
    {
      "metadata": {
        "id": "6jo8N1p2lpFe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Processamento com Multi-GPU e paralelismo de dados\n",
        "\n",
        "Caso você esteja escrevendo um _software_ em uma linguagem como C++ para um computador com um só processador, fazê-lo rodar em multiplas GPUs em paralelo requereria reescrever o software do zero. Porém esse não é o caso com TensorFlow. Por conta de sua natureza simbólica, TensorFlow pode esconder toda essa complexidade, tornando fácil escalar seu programa entre multiplos CPUs e GPUs."
      ]
    },
    {
      "metadata": {
        "id": "_xNvmstElr89",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Comecemos por um exemplo simples de adição de dois vetores em uma CPU:\n"
      ]
    },
    {
      "metadata": {
        "id": "tFvAqkqWlt0z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with tf.device(tf.DeviceSpec(device_type=\"CPU\", device_index=0)):\n",
        "   a = tf.random_uniform([1000, 100])\n",
        "   b = tf.random_uniform([1000, 100])\n",
        "   c = a + b\n",
        "\n",
        "tf.Session().run(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aHAMfx6hlwt3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A mesma operação pode ser feita de maneira simples em uma GPU:"
      ]
    },
    {
      "metadata": {
        "id": "KuhFslNFlzwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=0)):\n",
        "    a = tf.random_uniform([1000, 100])\n",
        "    b = tf.random_uniform([1000, 100])\n",
        "    c = a + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dt9p12K0l4WO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mas e se você possui duas GPUs e queira utilizar ambas? Para fazer isso, podemos separar os dados e usar uma GPU separada para precessar cada metade:"
      ]
    },
    {
      "metadata": {
        "id": "8BUOtJmMl6R_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "split_a = tf.split(a, 2)\n",
        "split_b = tf.split(b, 2)\n",
        "\n",
        "split_c = []\n",
        "for i in range(2):\n",
        "    with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
        "        split_c.append(split_a[i] + split_b[i])\n",
        "\n",
        "c = tf.concat(split_c, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VQuDYJ9Ml8Lk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos escrever isso de uma maneira mais generalizada para que possamos substituir a operação de adição por qualquer outra operação:"
      ]
    },
    {
      "metadata": {
        "id": "VXZsCdvCmEaf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_parallel(fn, num_gpus, **kwargs):\n",
        "    in_splits = {}\n",
        "    for k, v in kwargs.items():\n",
        "        in_splits[k] = tf.split(v, num_gpus)\n",
        "\n",
        "    out_split = []\n",
        "    for i in range(num_gpus):\n",
        "        with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
        "            with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
        "                out_split.append(fn(**{k : v[i] for k, v in in_splits.items()}))\n",
        "\n",
        "    return tf.concat(out_split, axis=0)\n",
        "\n",
        "\n",
        "def model(a, b):\n",
        "    return a + b\n",
        "\n",
        "c = make_parallel(model, 2, a=a, b=b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tIycNFWRmFPU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Você pode substituir o modelo por qualquer função que tenha como entrada uma série de tensores e retorne um tensor como resultado com a condição que ambps, entrada e saída estejam em _batchs_. Note que nós também adicionamos um alcance variável e setamos a reutilização como verdadeiro. Isso garante que utilizaremos as mesmas variáveis para processar as duas metades. Isso será útil no nosso próximo exemplo.\n",
        "\n",
        "Vejamos um exemplo um pouco mais prático. Queremos treinar a rede neural em multiplos GPUs. Durante o treinamento nós não somente necessitamos calcular o passo à frente como também precisa calcular o passo atrás (os gradientes). porém como podemos paralelizar o cálculo do gradiente? Isso acaba por ser bastante simples.\n",
        "\n",
        "Lembre-se do primeiro item que nós queríamos treinar um polinômio de segunda ordem para algumas amostras. Organizamos um pouco o código para ter uma pilha das operações na função modelo:"
      ]
    },
    {
      "metadata": {
        "id": "nN-NH42TmHiP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def model(x, y):\n",
        "    w = tf.get_variable(\"w\", shape=[3, 1])\n",
        "\n",
        "    f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1)\n",
        "    yhat = tf.squeeze(tf.matmul(f, w), 1)\n",
        "\n",
        "    loss = tf.square(yhat - y)\n",
        "    return loss\n",
        "\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = tf.placeholder(tf.float32)\n",
        "\n",
        "loss = model(x, y)\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(0.1).minimize(\n",
        "    tf.reduce_mean(loss))\n",
        "\n",
        "def generate_data():\n",
        "    x_val = np.random.uniform(-10.0, 10.0, size=100)\n",
        "    y_val = 5 * np.square(x_val) + 3\n",
        "    return x_val, y_val\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for _ in range(1000):\n",
        "    x_val, y_val = generate_data()\n",
        "    _, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})\n",
        "\n",
        "_, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})\n",
        "print(sess.run(tf.contrib.framework.get_variables_by_name(\"w\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0vzGA6WHmJrV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora vamos usar `make_parallel` que escrevemos para paralelizar. Precisamos modificar somente duas linhas de código do código acima:"
      ]
    },
    {
      "metadata": {
        "id": "A72CzAQcmLp1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = make_parallel(model, 2, x=x, y=y)\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(0.1).minimize(\n",
        "    tf.reduce_mean(loss),\n",
        "    colocate_gradients_with_ops=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BrGnPdANmN7E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A unica coisa que precisamos para mudar para paralelizar o _backpropagation_ de gradientes é colocar a flag `colocate_gradients_with_ops` como verdadeiro. Para assegurar que a operação de gradiente rode na mesma GPU que a operação original."
      ]
    },
    {
      "metadata": {
        "id": "pbZT9PtfmS8R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Debugando modelos TensorFlow\n",
        "\n",
        "A natureza simbólica do TensorFlow o torna relativamente mais difícil de debugar em comparação com código python regular. Aqui introduzimos algumas ferramentas incluídas no TensorFlow para tornar a tarefa de debugar mais fácil."
      ]
    },
    {
      "metadata": {
        "id": "N7zZaiV6mXda",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Provavelmente o erro mais comum que se pode fazer ao utilizar TensorFlow é passar tensores de tamanhos errados às operações. Muitas operações do TensorFlow podem operar com tensores de ranks e tamanhos diferentes. Isso pode ser conveniente quando se utiliza uma API, porém pode causar dor de cabeça quando as coisas dão errado.\n",
        "\n",
        "Por exemplo, considere a operação `tf.matmul`, que multiplica duas matrizes:"
      ]
    },
    {
      "metadata": {
        "id": "sOjviDPQmbzJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.random_uniform([2, 3])\n",
        "b = tf.random_uniform([3, 4])\n",
        "c = tf.matmul(a, b)  # c is a tensor of shape [2, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AobiIGCmdWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Porém a mesma função também faz multiplicação matricial em _batch_:"
      ]
    },
    {
      "metadata": {
        "id": "FScEHaf9me83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.random_uniform([10, 2, 3])\n",
        "b = tf.random_uniform([10, 3, 4])\n",
        "tf.matmul(a, b)  # c is a tensor of shape [10, 2, 4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsDnTDc9mih5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Outro exemplo que discutimos antes na seção de difusão é a operação de adição que suporta difusão:"
      ]
    },
    {
      "metadata": {
        "id": "8ugA2wdFnTNG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1.], [2.]])\n",
        "b = tf.constant([1., 2.])\n",
        "c = a + b  # c is a tensor of shape [2, 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hoYw8cbdnf7C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Validando seus tensores com operações `tf.assert*` "
      ]
    },
    {
      "metadata": {
        "id": "1iUZBJf8nltZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uma maneira de reduzir as chances de comportamento indesejado é verificar explicitamente o rank ou dimensão de tensores intermediários com operações `tf.assert*`."
      ]
    },
    {
      "metadata": {
        "id": "xlhHfw8ZnnpP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1.], [2.]])\n",
        "b = tf.constant([1., 2.])\n",
        "check_a = tf.assert_rank(a, 1)  # This will raise an InvalidArgumentError exception\n",
        "check_b = tf.assert_rank(b, 1)\n",
        "with tf.control_dependencies([check_a, check_b]):\n",
        "    c = a + b  # c is a tensor of shape [2, 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYrxpUUtnqAi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lembre-se que nós de afirmação, assim como outras operações são parte do grafo e se não from avaliados são podado durante `Session.run()`. Portanto assegure-se de criar dependências explícitas para operações de afirmação, para forçar o TensorFlow a executá-los.\n",
        "\n",
        "Você pode também  afirmações para validar o valore de tensores no _runtime_:"
      ]
    },
    {
      "metadata": {
        "id": "LXJZgpRZntxY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "check_pos = tf.assert_positive(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QEtMnFMynv1J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Veja os documentos oficiais para [lista completa de operações de afirmação](https://github.com/tensorflow/docs/tree/master/site/en/api_guides/python).\n"
      ]
    },
    {
      "metadata": {
        "id": "EiK5y2PTn9tZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Registrando valores de tensores com `tf.Print`"
      ]
    },
    {
      "metadata": {
        "id": "Yu-Y6jutoBvL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Outra função inerente útil para debugar é `tf.Print` que registra os tensores dados para o erro padrão:"
      ]
    },
    {
      "metadata": {
        "id": "ppMtD1e2oD61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_copy = tf.Print(input, tensors_to_print_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5edNRSk6oGH-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note que `tf.Print` retorna a cópia de seu primeiro argumento como uma saída. Uma maneira de forçar `tf.Print` a rodar é passar sua saída para outra operação que seja executada. Por exemplo, se você quer escrever o valor dos tensores a e b antes de adicionar então poderiamos fazer algo assim:"
      ]
    },
    {
      "metadata": {
        "id": "d6L3zwE_oIKM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a = ...\n",
        "b = ...\n",
        "a = tf.Print(a, [a, b])\n",
        "c = a + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5fu8-yg5oKg_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Alternativamente podemos manualmente definir o controle de dependência."
      ]
    },
    {
      "metadata": {
        "id": "hWQS9w75oMqj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Checando o gradiente com `tf.compute_gradient_error`\n",
        "\n",
        "Nem todas as operações de TensorFlow vêm com gradientes, e é facil construir graphs (não intencionalemente) para o qual TensorFlow não consegue calcular os gradientes.\n"
      ]
    },
    {
      "metadata": {
        "id": "b3LF1bGmoPMF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vejamos um exemplo:"
      ]
    },
    {
      "metadata": {
        "id": "3ydLfrfpoYtu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def non_differentiable_softmax_entropy(logits):\n",
        "    probs = tf.nn.softmax(logits)\n",
        "    return tf.nn.softmax_cross_entropy_with_logits(labels=probs, logits=logits)\n",
        "\n",
        "w = tf.get_variable(\"w\", shape=[5])\n",
        "y = -non_differentiable_softmax_entropy(w)\n",
        "\n",
        "opt = tf.train.AdamOptimizer()\n",
        "train_op = opt.minimize(y)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for i in range(10000):\n",
        "    sess.run(train_op)\n",
        "\n",
        "print(sess.run(tf.nn.softmax(w)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dhtZ1CzUoawp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Estamos utilizando `tf.softmax_cross_entropy_with_logits` para definier a entropia de uma distribuição categórica. E por fim utilizamos o otimizador Adam para encontrar os pesos com máxima entropia. Se você fez um curso de teoria da informação, você saberia que distribuição uniforme contem máxima entropia. Portanto esperaria-se que o resultado fosse [0.2, 0.2, 0.2, 0.2, 0.2]. Porém caso você rode isso, o resultado gerado pode ser algo inesperado como:"
      ]
    },
    {
      "metadata": {
        "id": "cbQ98k2nodA6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[ 0.34081486  0.24287023  0.23465775  0.08935683  0.09230034]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gbV31Ih4off_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Acontece que `tf.nn.softmax_cross_entropy_with_logits` tem gradiente indefinido no que dis relação aos rótulos! Porém como podemos identificar esse erro se não soubessemos disso?\n",
        "\n",
        "Felizmente para nós, TensorFlow vem com um diferenciador numérico que pode ser utilizado para encontrar erro simbólicos em gradientes. Vejamos como isso funciona:"
      ]
    },
    {
      "metadata": {
        "id": "DxsDU-Faoj3q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with tf.Session():\n",
        "    diff = tf.test.compute_gradient_error(w, [5], y, [])\n",
        "    print(diff)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qBF10hfFoltS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se você rodar isso, você verá que a diferença entre os gradientes numérico e simbólico é consideravelmente altas (0.06 - 0.1 nas minhas tentativas).\n",
        "\n",
        "Agora vamos corrigir nossa função com uma versão diferenciável da entropia e chegar outra vez:"
      ]
    },
    {
      "metadata": {
        "id": "TWeVELt9ontp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def softmax_entropy(logits, dim=-1):\n",
        "    plogp = tf.nn.softmax(logits, dim) * tf.nn.log_softmax(logits, dim)\n",
        "    return -tf.reduce_sum(plogp, dim)\n",
        "\n",
        "w = tf.get_variable(\"w\", shape=[5])\n",
        "y = -softmax_entropy(w)\n",
        "\n",
        "print(w.get_shape())\n",
        "print(y.get_shape())\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    diff = tf.test.compute_gradient_error(w, [5], y, [])\n",
        "    print(diff)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAVMCGhGoqwk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A diferença deve ser ~0.0001 o que é muito melhor.\n",
        "\n",
        "Agora se rodarmos o otimizador outra vez com a versão correta podemos que os pesos finais são:"
      ]
    },
    {
      "metadata": {
        "id": "YTYx9NF3ostT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[ 0.2  0.2  0.2  0.2  0.2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-T641oQoukQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O que é exatamente o que esperávamos.\n",
        "\n",
        "[Sumário TensorFlow](https://github.com/tensorflow/docs/tree/master/site/en/api_guides/python), e [tfdbg (TensorFlow Debugger)](https://github.com/tensorflow/docs/tree/master/site/en/api_guides/python) são outras ferramentas que podem ser utilizadas para debugar. Por favor vá aos documentos oficiais para aprender mais."
      ]
    },
    {
      "metadata": {
        "id": "YI1KBdtdXeyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Estabilidade numérica em TensorFlow\n",
        "\n",
        "Ao utilizar qualquer módulo de computação numérica como NumPy ou TensorFlow, é importante atentar-se que escrever o código matematicamente correto, não necessariamente leva a resultados corretos. Também se faz necessário assegurar-se que os cálculos são estáveis."
      ]
    },
    {
      "metadata": {
        "id": "xCJFYhF6XlH2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos começar com um exemplo simples. Desde o ensino fundamental sabemos que x*y/y é igual a x para qualquer valor de x diferente de zero. Porém vejamos se isso é sempre verdade na prática:"
      ]
    },
    {
      "metadata": {
        "id": "p9iX9X6rXm6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.float32(1)\n",
        "\n",
        "y = np.float32(1e-50)  # y would be stored as zero\n",
        "z = x * y / y\n",
        "\n",
        "print(z)  # prints nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BOQyg6jWXpNJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A razão para o resultado incorreto é simplesmente que y é muito pequeno para um tipo float32. Um problema similar ocorre também quando y é muito grande:"
      ]
    },
    {
      "metadata": {
        "id": "nFP_FRzvXsFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = np.float32(1e39)  # y would be stored as inf\n",
        "z = x * y / y\n",
        "\n",
        "print(z)  # prints 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_eDZZRZXtq7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O menor número positivo que o tipo float32 pode representar é 1.4013e-45 e qualquer valor menor é guardado como zero. Da mesma maneira, qualquer número acima de 3.40282e+38 é guardado como infinito."
      ]
    },
    {
      "metadata": {
        "id": "gW4VjRvkX0gd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.nextafter(np.float32(0), np.float32(1)))  # prints 1.4013e-45\n",
        "print(np.finfo(np.float32).max)  # print 3.40282e+38"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQthMB8nX5FL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para assegurar-se que seus cálculos são estáveis, é preciso evitar valores muito pequeno ou muito grandes. Isso pode soar um pouco óbvio, porém esse tipo de problema pode ser extremamente difícil de debugar, especialmente quando se está usando gradiente descendente em TensorFlow. Isso porque você não somente tem que se assegurar que todos os valores no caminho direto estão em um intervalo válido, assim como tem que se assegurar que no caminho inverso (durante o cálculo de gradiente) também estejam em um intervalo válido.\n",
        "\n",
        "Vejamos um exemplo real. Queremos calcular o softmax de um vetor de [logits](https://pt.wikipedia.org/wiki/Logit). Uma implementação \n",
        "ingênua seria algo mais ou menos assim:"
      ]
    },
    {
      "metadata": {
        "id": "91ULP8LpX61_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def unstable_softmax(logits):\n",
        "    exp = tf.exp(logits)\n",
        "    return exp / tf.reduce_sum(exp)\n",
        "\n",
        "tf.Session().run(unstable_softmax([1000., 0.]))  # prints [ nan, 0.]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hRzjIFz3X9AD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note que calcular a exonencial de logits para valores relativamente pequenos resulta em resultados gigantes que estão fora do intervalo do float32. O maior valor logit para nossa implementação ingênua do softmax é ln(3.40282e+38) = 88.7, qualquer coisa acima disso retornaria NaN.\n",
        "\n",
        "Mas como podemos fazê-la mais estável? A solução é bastante simples. É fácil ver que exp(x - c) / ∑ exp(x - c) = exp(x) / ∑ exp(x). Portanto podemos subtrair qualquer constante do resultado logit e o resultado permanece o mesmo. Escolhemos essa constante para ser o máximo de logits. Dessa forma o domínio da função exponencial seria limitado a [-inf,0], e consequentemente seu intervalo seria [0.0,1.0], o que é desejável:"
      ]
    },
    {
      "metadata": {
        "id": "_G-z8BpGX_FE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def softmax(logits):\n",
        "    exp = tf.exp(logits - tf.reduce_max(logits))\n",
        "    return exp / tf.reduce_sum(exp)\n",
        "\n",
        "tf.Session().run(softmax([1000., 0.]))  # prints [ 1., 0.]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tJLulxIYCd4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vejamos um caso mais complicado. Considere que temos um problema de classificação. Usamos a função softmax para produzir as probabilidades de nossos logits. Definimos a função de perda ara ser a entropia cruzada entre a predição e os rótulos. Lembre-se que a entropia cruzada para uma distribuição categórica pode ser definida como xe(p, q) = -∑ p_i log(q_i). Portanto uma implementação ingênua da entropia cruzada seria algo como:"
      ]
    },
    {
      "metadata": {
        "id": "lyUc7oxmYEj4",
        "colab_type": "code",
        "outputId": "376756da-6d7d-4f3d-8edd-4db8b8924610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "cell_type": "code",
      "source": [
        "def unstable_softmax_cross_entropy(labels, logits):\n",
        "    logits = tf.log(softmax(logits))\n",
        "    return -tf.reduce_sum(labels * logits)\n",
        "\n",
        "labels = tf.constant([0.5, 0.5])\n",
        "logits = tf.constant([1000., 0.])\n",
        "\n",
        "xe = unstable_softmax_cross_entropy(labels, logits)\n",
        "\n",
        "print(tf.Session().run(xe))  # prints inf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b8f0b41f6b2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vwTNuE0CYGhA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note que nessa implementação que à medida que a saída do softmax se aproxima do zero, o regristo de saída se aproxima de infinito o que causa instabilidade na computação. Podemos reescrever essa função expandindo o softmax e fazendo algumas simplificções:"
      ]
    },
    {
      "metadata": {
        "id": "2xRB5OzZYImZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax_cross_entropy(labels, logits):\n",
        "    scaled_logits = logits - tf.reduce_max(logits)\n",
        "    normalized_logits = scaled_logits - tf.reduce_logsumexp(scaled_logits)\n",
        "    return -tf.reduce_sum(labels * normalized_logits)\n",
        "\n",
        "labels = tf.constant([0.5, 0.5])\n",
        "logits = tf.constant([1000., 0.])\n",
        "\n",
        "xe = softmax_cross_entropy(labels, logits)\n",
        "\n",
        "print(tf.Session().run(xe))  # prints 500.0\n",
        "\n",
        "We can also verify that the gradients are also computed correctly:\n",
        "\n",
        "g = tf.gradients(xe, logits)\n",
        "print(tf.Session().run(g))  # prints [0.5, -0.5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62ZOwx44YK86",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O que é correto.\n",
        "\n",
        "Deixe-me lebrar-lhes outra vez que cuidado extra tem de ser tomado quando se usa gradiente descendente para se assegurar que o intervalo de valores que a função está utilizando, assim como seus gradientes para cada camada estão dentro do intervalo de estabilidade. Funções exponencial e logarítimo quando utilizadas ingenuamente são especialmente problemáticas porque podem variar de valores muito pequenos a valores muito grandes rapidamente."
      ]
    },
    {
      "metadata": {
        "id": "vHhPWzp2YNmQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Construindo um framework de treinamento de rede neural com API _learn_\n",
        "\n",
        "Por simplicidade, na maioria dos exemplos aqui executados nós criamos sessões manualmente e não nos preocupamos em salvar e carregar _checkpoints_ porém normalmente não fazemos assim na prática. Você provavelmente quererá usar o API _learn_ para cuidar do gerenciamento e registro de sessões. Nós fornecemos um framework simples porém prático para treinamento de redes neurais utilizando TensorFlow. Nesse item explicaremos como esse framework funciona.\n",
        "\n",
        "Ao se trabalhar com modelos de redes neurais normalmente tem-se uma separação do conjunto de treino e de teste. Treina-se o modelo com o conjunto de treion, e de vez em quando avalia-se junto ao conjunto de teste e calcula-se as métricas. Também é necessário salvar os parâmetros do modelo como um _checkpoint_, e idealmente espera-se ser capaz de parar e retomar o treinamento de qualquer ponto. O API _learn_ do TensorFlow é feito para tornar essa tarefa mais simples, deixando-nos livres para focar no desenvolvimento do modelo em si."
      ]
    },
    {
      "metadata": {
        "id": "KB7sriVaYTo_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A forma mais básica de usar o API `tf.learn` é usando o objeto `tf.Estimator` diretamente. É necessário definir um model que defina a função de perda, a operação de treino, um ou um conjunto de predições, e um conjunto de métricas de avaliação (opcional):"
      ]
    },
    {
      "metadata": {
        "id": "SHo10YPAYVhv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    predictions = ...\n",
        "    loss = ...\n",
        "    train_op = ...\n",
        "    metric_ops = ...\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions=predictions,\n",
        "        loss=loss,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops=metric_ops)\n",
        "\n",
        "params = ...\n",
        "run_config = tf.contrib.learn.RunConfig(model_dir=FLAGS.output_dir)\n",
        "estimator = tf.estimator.Estimator(\n",
        "    model_fn=model_fn, config=run_config, params=params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zROura6CYYmS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para treinar o modelo basta simplesmente chamar a função `Estimator.train()` inserindo uma função de entrada para leitura dos dados:"
      ]
    },
    {
      "metadata": {
        "id": "48TE9LgyYcns",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn():\n",
        "    features = ...\n",
        "    labels = ...\n",
        "    return features, labels\n",
        "\n",
        "estimator.train(input_fn=input_fn, max_steps=...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-372i0i_YeMe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "E para avaliar o modelo basta chamar `Estimator.evaluate()`:"
      ]
    },
    {
      "metadata": {
        "id": "SvN630f4YhBt",
        "colab_type": "code",
        "outputId": "0c6c8234-4804-4e14-abd5-e3b9bfc039f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "estimator.evaluate(input_fn=input_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-27863659c21c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3-dJFawBYi61",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O objeto `Estimator` pode ser bom o suficiente para casos simples, portém TensorFlow fornece um objeto de maior hierarquia chamado `Experiment` que fornece alguma funcionalidades adicionais. Criando um objeto `Experiment` é muito fácil:"
      ]
    },
    {
      "metadata": {
        "id": "5NWhsRi2YkZb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "experiment = tf.contrib.learn.Experiment(\n",
        "    estimator=estimator,\n",
        "    train_input_fn=train_input_fn,\n",
        "    eval_input_fn=eval_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-kMNdpDYlv7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora podemos chamar a função `train_and_evaluate` para calcular as métricas enquanto treina:"
      ]
    },
    {
      "metadata": {
        "id": "czlcD3SSYoMw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "experiment.train_and_evaluate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsfY4qArYsGK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uma maneira ainda mais alto nível de rodar experimento é usando a função `learn_runner.run()`. Assim fica a função principal:"
      ]
    },
    {
      "metadata": {
        "id": "b4wFZ1xuYtmc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.flags.DEFINE_string(\"output_dir\", \"\", \"Optional output dir.\")\n",
        "tf.flags.DEFINE_string(\"schedule\", \"train_and_evaluate\", \"Schedule.\")\n",
        "tf.flags.DEFINE_string(\"hparams\", \"\", \"Hyper parameters.\")\n",
        "\n",
        "FLAGS = tf.flags.FLAGS\n",
        "\n",
        "def experiment_fn(run_config, hparams):\n",
        "  estimator = tf.estimator.Estimator(\n",
        "    model_fn=make_model_fn(),\n",
        "    config=run_config,\n",
        "    params=hparams)\n",
        "  return tf.contrib.learn.Experiment(\n",
        "    estimator=estimator,\n",
        "    train_input_fn=make_input_fn(tf.estimator.ModeKeys.TRAIN, hparams),\n",
        "    eval_input_fn=make_input_fn(tf.estimator.ModeKeys.EVAL, hparams))\n",
        "\n",
        "def main(unused_argv):\n",
        "  run_config = tf.contrib.learn.RunConfig(model_dir=FLAGS.output_dir)\n",
        "  hparams = tf.contrib.training.HParams()\n",
        "  hparams.parse(FLAGS.hparams)\n",
        "\n",
        "  estimator = tf.contrib.learn.learn_runner.run(\n",
        "    experiment_fn=experiment_fn,\n",
        "    run_config=run_config,\n",
        "    schedule=FLAGS.schedule,\n",
        "    hparams=hparams)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  tf.app.run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bqdc6sGYYv_b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A flag `schedule` decide qual função membro do objeto `Experiment` é chamado. Portanto, se você por exemplo setar `schedule` para \"train_and_evaluate\", `experiment.train_and_evaluate()` seria chamado.\n",
        "\n",
        "A função de entrada retorna dois tensores (ou dicionário de tensores) fornecendo os recursos e rótulos a serem passados para o modelo:"
      ]
    },
    {
      "metadata": {
        "id": "mhhYr2g3Yy77",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn():\n",
        "    features = ...\n",
        "    labels = ...\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LcuhiEnLY1CK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Veja [mnist.py](https://github.com/vahidk/TensorflowFramework/blob/master/dataset/mnist.py) para exemplo de como ler os dados com o API dataset. Para aprender diferentes maneiras de ler os dados em TensorFlow leia [esse item](https://github.com/vahidk/EffectiveTensorflow#data).  \n",
        "\n",
        "O framework também vem com uma simples rede de classificação convulocional em [alexnet.py](https://github.com/vahidk/TensorflowFramework/blob/master/model/alexnet.py) que inclui um exemplo.\n",
        "\n",
        "Isso é tudo! Isso é tudo o que se necessita para começar com o API _learn_ de TensorFlow. Recomendo analisar o [código fonte](https://github.com/vahidk/TensorFlowFramework) do framework e visitar o API python oficial para aprender mais sobre o API _learn_."
      ]
    },
    {
      "metadata": {
        "id": "maVOt7WAa6-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Parte II: Cookbook\n",
        "\n",
        "Essa seção inclui a implementação de várias operações comuns em TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "c2aXYshEbYqE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Verificar Dimensão"
      ]
    },
    {
      "metadata": {
        "id": "mcJgWfTYbpXN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_shape(tensor):\n",
        "  \"\"\"Returns static shape if available and dynamic shape otherwise.\"\"\"\n",
        "  static_shape = tensor.shape.as_list()\n",
        "  dynamic_shape = tf.unstack(tf.shape(tensor))\n",
        "  dims = [s[1] if s[0] is None else s[0]\n",
        "          for s in zip(static_shape, dynamic_shape)]\n",
        "  return dims"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pvtvCXyxbsMT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Obter _Batch_"
      ]
    },
    {
      "metadata": {
        "id": "nfnzjKZacHn1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_gather(tensor, indices):\n",
        "  \"\"\"Gather in batch from a tensor of arbitrary size.\n",
        "\n",
        "  In pseudocode this module will produce the following:\n",
        "  output[i] = tf.gather(tensor[i], indices[i])\n",
        "\n",
        "  Args:\n",
        "    tensor: Tensor of arbitrary size.\n",
        "    indices: Vector of indices.\n",
        "  Returns:\n",
        "    output: A tensor of gathered values.\n",
        "  \"\"\"\n",
        "  shape = get_shape(tensor)\n",
        "  flat_first = tf.reshape(tensor, [shape[0] * shape[1]] + shape[2:])\n",
        "  indices = tf.convert_to_tensor(indices)\n",
        "  offset_shape = [shape[0]] + [1] * (indices.shape.ndims - 1)\n",
        "  offset = tf.reshape(tf.range(shape[0]) * shape[1], offset_shape)\n",
        "  output = tf.gather(flat_first, indices + offset)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6eK_rngceCQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Beam Search"
      ]
    },
    {
      "metadata": {
        "id": "PCWct7cIciqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def rnn_beam_search(update_fn, initial_state, sequence_length, beam_width,\n",
        "                    begin_token_id, end_token_id, name=\"rnn\"):\n",
        "  \"\"\"Beam-search decoder for recurrent models.\n",
        "\n",
        "  Args:\n",
        "    update_fn: Function to compute the next state and logits given the current\n",
        "               state and ids.\n",
        "    initial_state: Recurrent model states.\n",
        "    sequence_length: Length of the generated sequence.\n",
        "    beam_width: Beam width.\n",
        "    begin_token_id: Begin token id.\n",
        "    end_token_id: End token id.\n",
        "    name: Scope of the variables.\n",
        "  Returns:\n",
        "    ids: Output indices.\n",
        "    logprobs: Output log probabilities probabilities.\n",
        "  \"\"\"\n",
        "  batch_size = initial_state.shape.as_list()[0]\n",
        "\n",
        "  state = tf.tile(tf.expand_dims(initial_state, axis=1), [1, beam_width, 1])\n",
        "\n",
        "  sel_sum_logprobs = tf.log([[1.] + [0.] * (beam_width - 1)])\n",
        "\n",
        "  ids = tf.tile([[begin_token_id]], [batch_size, beam_width])\n",
        "  sel_ids = tf.zeros([batch_size, beam_width, 0], dtype=ids.dtype)\n",
        "\n",
        "  mask = tf.ones([batch_size, beam_width], dtype=tf.float32)\n",
        "\n",
        "  for i in range(sequence_length):\n",
        "    with tf.variable_scope(name, reuse=True if i > 0 else None):\n",
        "\n",
        "      state, logits = update_fn(state, ids)\n",
        "      logits = tf.nn.log_softmax(logits)\n",
        "\n",
        "      sum_logprobs = (\n",
        "          tf.expand_dims(sel_sum_logprobs, axis=2) +\n",
        "          (logits * tf.expand_dims(mask, axis=2)))\n",
        "\n",
        "      num_classes = logits.shape.as_list()[-1]\n",
        "\n",
        "      sel_sum_logprobs, indices = tf.nn.top_k(\n",
        "          tf.reshape(sum_logprobs, [batch_size, num_classes * beam_width]),\n",
        "          k=beam_width)\n",
        "\n",
        "      ids = indices % num_classes\n",
        "\n",
        "      beam_ids = indices // num_classes\n",
        "\n",
        "      state = batch_gather(state, beam_ids)\n",
        "\n",
        "      sel_ids = tf.concat([batch_gather(sel_ids, beam_ids),\n",
        "                           tf.expand_dims(ids, axis=2)], axis=2)\n",
        "\n",
        "      mask = (batch_gather(mask, beam_ids) *\n",
        "              tf.to_float(tf.not_equal(ids, end_token_id)))\n",
        "\n",
        "  return sel_ids, sel_sum_logprobs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNu0E8t4cl74",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Combinar - Merge"
      ]
    },
    {
      "metadata": {
        "id": "dRp336suc11V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def merge(tensors, units, activation=tf.nn.relu, name=None, **kwargs):\n",
        "  \"\"\"Merge features with broadcasting support.\n",
        "\n",
        "  This operation concatenates multiple features of varying length and applies\n",
        "  non-linear transformation to the outcome.\n",
        "\n",
        "  Example:\n",
        "    a = tf.zeros([m, 1, d1])\n",
        "    b = tf.zeros([1, n, d2])\n",
        "    c = merge([a, b], d3)  # shape of c would be [m, n, d3].\n",
        "\n",
        "  Args:\n",
        "    tensors: A list of tensor with the same rank.\n",
        "    units: Number of units in the projection function.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(name, default_name=\"merge\"):\n",
        "    # Apply linear projection to input tensors.\n",
        "    projs = []\n",
        "    for i, tensor in enumerate(tensors):\n",
        "      proj = tf.layers.dense(\n",
        "          tensor, units, activation=None,\n",
        "          name=\"proj_%d\" % i,\n",
        "          **kwargs)\n",
        "      projs.append(proj)\n",
        "\n",
        "    # Compute sum of tensors.\n",
        "    result = projs.pop()\n",
        "    for proj in projs:\n",
        "      result = result + proj\n",
        "\n",
        "    # Apply nonlinearity.\n",
        "    if activation:\n",
        "      result = activation(result)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g_9JviGuc4jN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Entropia"
      ]
    },
    {
      "metadata": {
        "id": "ZBDip6xHc6ak",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def softmax_entropy(logits, dim=-1):\n",
        "  \"\"\"Compute entropy over specified dimensions.\"\"\"\n",
        "  plogp = tf.nn.softmax(logits, dim) * tf.nn.log_softmax(logits, dim)\n",
        "  return -tf.reduce_sum(plogp, dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BbIau13Dc91W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Divergência-KL"
      ]
    },
    {
      "metadata": {
        "id": "k_jF8DjadCeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gaussian_kl(q, p=(0., 0.)):\n",
        "  \"\"\"Computes KL divergence between two isotropic Gaussian distributions.\n",
        "\n",
        "  To ensure numerical stability, this op uses mu, log(sigma^2) to represent\n",
        "  the distribution. If q is not provided, it's assumed to be unit Gaussian.\n",
        "\n",
        "  Args:\n",
        "    q: A tuple (mu, log(sigma^2)) representing a multi-variatie Gaussian.\n",
        "    p: A tuple (mu, log(sigma^2)) representing a multi-variatie Gaussian.\n",
        "  Returns:\n",
        "    A tensor representing KL(q, p).\n",
        "  \"\"\"\n",
        "  mu1, log_sigma1_sq = q\n",
        "  mu2, log_sigma2_sq = p\n",
        "  return tf.reduce_sum(\n",
        "    0.5 * (log_sigma2_sq - log_sigma1_sq +\n",
        "           tf.exp(log_sigma1_sq - log_sigma2_sq) +\n",
        "           tf.square(mu1 - mu2) / tf.exp(log_sigma2_sq) -\n",
        "           1), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RbjZn1ddGfg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Paralelizar"
      ]
    },
    {
      "metadata": {
        "id": "-BDZuvHjdLRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_parallel(fn, num_gpus, **kwargs):\n",
        "  \"\"\"Parallelize given model on multiple gpu devices.\n",
        "\n",
        "  Args:\n",
        "    fn: Arbitrary function that takes a set of input tensors and outputs a\n",
        "        single tensor. First dimension of inputs and output tensor are assumed\n",
        "        to be batch dimension.\n",
        "    num_gpus: Number of GPU devices.\n",
        "    **kwargs: Keyword arguments to be passed to the model.\n",
        "  Returns:\n",
        "    A tensor corresponding to the model output.\n",
        "  \"\"\"\n",
        "  in_splits = {}\n",
        "  for k, v in kwargs.items():\n",
        "    in_splits[k] = tf.split(v, num_gpus)\n",
        "\n",
        "  out_split = []\n",
        "  for i in range(num_gpus):\n",
        "    with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
        "      with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
        "        out_split.append(fn(**{k : v[i] for k, v in in_splits.items()}))\n",
        "\n",
        "  return tf.concat(out_split, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iVgoO-6EdOFF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##ReLU simples"
      ]
    },
    {
      "metadata": {
        "id": "_vqVjLfmdUso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def leaky_relu(tensor, alpha=0.1):\n",
        "    \"\"\"Computes the leaky rectified linear activation.\"\"\"\n",
        "    return tf.maximum(tensor, alpha * tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49aml-S6dXLy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Normalização de _Batch_"
      ]
    },
    {
      "metadata": {
        "id": "gCjadZmudaIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batch_normalization(tensor, training=False, epsilon=0.001, momentum=0.9, \n",
        "                        fused_batch_norm=False, name=None):\n",
        "  \"\"\"Performs batch normalization on given 4-D tensor.\n",
        "  \n",
        "  The features are assumed to be in NHWC format. Noe that you need to \n",
        "  run UPDATE_OPS in order for this function to perform correctly, e.g.:\n",
        "\n",
        "  with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "    train_op = optimizer.minimize(loss)\n",
        "\n",
        "  Based on: https://arxiv.org/abs/1502.03167\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(name, default_name=\"batch_normalization\"):\n",
        "    channels = tensor.shape.as_list()[-1]\n",
        "    axes = list(range(tensor.shape.ndims - 1))\n",
        "\n",
        "    beta = tf.get_variable(\n",
        "      'beta', channels, initializer=tf.zeros_initializer())\n",
        "    gamma = tf.get_variable(\n",
        "      'gamma', channels, initializer=tf.ones_initializer())\n",
        "\n",
        "    avg_mean = tf.get_variable(\n",
        "      \"avg_mean\", channels, initializer=tf.zeros_initializer(),\n",
        "      trainable=False)\n",
        "    avg_variance = tf.get_variable(\n",
        "      \"avg_variance\", channels, initializer=tf.ones_initializer(),\n",
        "      trainable=False)\n",
        "\n",
        "    if training:\n",
        "      if fused_batch_norm:\n",
        "        mean, variance = None, None\n",
        "      else:\n",
        "        mean, variance = tf.nn.moments(tensor, axes=axes)\n",
        "    else:\n",
        "      mean, variance = avg_mean, avg_variance\n",
        "   \n",
        "    if fused_batch_norm:\n",
        "      tensor, mean, variance = tf.nn.fused_batch_norm(\n",
        "        tensor, scale=gamma, offset=beta, mean=mean, variance=variance, \n",
        "        epsilon=epsilon, is_training=training)\n",
        "    else:\n",
        "      tensor = tf.nn.batch_normalization(\n",
        "        tensor, mean, variance, beta, gamma, epsilon)\n",
        "\n",
        "    if training:\n",
        "      update_mean = tf.assign(\n",
        "        avg_mean, avg_mean * momentum + mean * (1.0 - momentum))\n",
        "      update_variance = tf.assign(\n",
        "        avg_variance, avg_variance * momentum + variance * (1.0 - momentum))\n",
        "\n",
        "      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_mean)\n",
        "      tf.add_to_collection(tf.GraphKeys.UPDATE_OPS, update_variance)\n",
        "\n",
        "  return tensor"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}